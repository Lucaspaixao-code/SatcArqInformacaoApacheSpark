{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa55564-d038-47c4-8a6e-891afd610979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType\n",
    "from delta import *\n",
    "import os\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-spark_2.12:3.2.0\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# A cada interação com a tabela 'carro_delta' serão criados arquivos dentro do diretório delta-lake/spark-warehouse/carro_delta.\n",
    "# Os arquivos consistem de dois tipos: '.parquet' e '.parquet.crc'.\n",
    "# Os arquivos '.parquet' é onde são salvos as informações em formato colunar, onde vão ser lidos de maneira eficiente pelo ambiente analítico.\n",
    "# Os arquivos '.parquet.crc' são arquivos de checksum que servem para validar a integridade dos arquivos '.parquet'. \n",
    "\n",
    "\n",
    "# ALTERAR ESSE CAMINHO DE FORMA QUE APONTE PARA ONDE O DIRETÓRIO DO TRABALHO ESTÁ LOCALIZADO NA SUA MÁQUINA\n",
    "file_base = 'file:////home/ed/SatcArqInformacaoApacheSpark/'\n",
    "\n",
    "\n",
    "fullpath = os.path.join(file_base, 'delta-lake', 'spark-warehouse', 'carro_delta')\n",
    "\n",
    "# CRIA A TABELA E A PASTA ONDE OS ARQUIVOS PARQUET SÃO SALVOS E EXIBE A TABELA SEM OS DADOS\n",
    "spark.sql(\n",
    "  f\"\"\"\n",
    "  CREATE OR REPLACE TABLE carro_delta (id INT, placa STRING) \n",
    "  USING delta \n",
    "  LOCATION '{fullpath}'\n",
    "  \"\"\"\n",
    ")\n",
    "spark.sql(\"select * from carro_delta\").show()\n",
    "\n",
    "# CARREGA O ARQUIVO DE HISTÓRICO DE ALTERAÇÕES E EXIBE\n",
    "from delta.tables import DeltaTable\n",
    "carro = DeltaTable.forPath(spark, \"./delta-lake/spark-warehouse/carro_delta\") # ESTE ENDEREÇO DEVE ESTAR COMPATÍVEL COM O ENDEREÇO fullpath\n",
    "carro.history().show()\n",
    "\n",
    "# INSERE DADOS DENTRO DA TABELA CRIADA ANTERIORMENTE E EXIBE\n",
    "spark.sql(\"INSERT INTO carro_delta VALUES (1, 'XYZ1J34'), (2, 'RLC5B93'), (3, 'ABV1V23')\")\n",
    "spark.sql(\"select * from carro_delta\").show()\n",
    "carro.history().show(truncate=False)\n",
    "\n",
    "# CRIA NOVAS COLUNAS NA TABELA E EXIBE\n",
    "spark.sql(\"\"\"alter table carro_delta add column marca STRING, modelo STRING, ano INT\"\"\")\n",
    "spark.sql(\"\"\"select * from carro_delta\"\"\").show()\n",
    "\n",
    "# REALIZA UPDATE DOS DADOS INSERIDOS ANTERIORMENTE E EXIBE\n",
    "spark.sql(\"\"\"update carro_delta set marca = 'Renault', modelo = 'Sandero', ano = 2021 where id = 1\"\"\")\n",
    "spark.sql(\"\"\"select * from carro_delta\"\"\").show()\n",
    "\n",
    "# REALIZA UPDATE DOS DADOS INSERIDOS ANTERIORMENTE E EXIBE\n",
    "spark.sql('update carro_delta set marca=\"GM\", modelo=\"tracker\", ano=2020 where id = 2')\n",
    "spark.sql('update carro_delta set marca=\"Ford\", modelo=\"EcoSport\", ano=2022 where id = 3')\n",
    "spark.sql('select * from carro_delta').show()\n",
    "\n",
    "# REALIZA EXIBIÇÃO DO HISTÓRICO DE ALTERAÇÕES DA TABELA carro_delta\n",
    "spark.sql('describe HISTORY carro_delta').show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
